{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main code taken from here https://github.com/bnsreenu/python_for_microscopists/blob/master/181_multivariate_timeseries_LSTM_GE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset without proportions (neg/pos) variables \n",
    "\n",
    "df = pd.read_csv('AllScorePerDay', index_col='dates')\n",
    "dfP = pd.read_csv('AllPropPword', index_col='dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying  pandemic terms dataset \n",
    "\n",
    "dfP = dfP.shift(1)\n",
    "dfP = dfP.fillna(np.mean(dfP))\n",
    "df['Pword'] = dfP['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variables, both datasets had 'holiday ouliers' in the same dates, so no need for manual codification\n",
    "\n",
    "df['holiday'] = 0\n",
    "df['covid'] = 0\n",
    "\n",
    "for index, score in enumerate(df['score']):\n",
    "    if score >0.04:\n",
    "        df['holiday'][index] = 1\n",
    "    if score < -0.18:\n",
    "        df['covid'][index] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differentiating main data and substituting \n",
    "\n",
    "df['score'] = df['score'].diff()\n",
    "df = df.fillna(np.mean(df['score'][:366]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df\n",
    "test = df[359:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train arrays and hyperparameter setting\n",
    "\n",
    "trainX = []\n",
    "trainY = []\n",
    "testX = []\n",
    "testY = []\n",
    "train  = np.array(train)\n",
    "test = np.array(test)\n",
    "n_future = 1\n",
    "n_past = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of arrays: 7 values and one target value\n",
    "\n",
    "for i in range(n_past, len(test)-n_future+1):\n",
    "    testX.append(test[i-n_past:i,0:test.shape[1]])\n",
    "    #testY.append(test[i+n_future-1:i+n_future,0])\n",
    "for i in range(n_past, len(train)-n_future+1):\n",
    "    trainX.append(train[i-n_past:i,0:train.shape[1]])\n",
    "    trainY.append(train[i+n_future-1:i+n_future,0])\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "testX = np.array(testX)\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM model creation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64,activation='relu',input_shape=(trainX.shape[1],trainX.shape[2]),return_sequences=True))\n",
    "model.add(LSTM(32,activation='relu',return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity-check for the arrrays created\n",
    "\n",
    "trainY[358] == df.iloc[365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model is stochastic so weights are either saved or kernel restarted to prevent the model from 'learning'\n",
    "\n",
    "Wsave = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(Wsave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dinamically, one-step-ahead polarity prediction\n",
    "\n",
    "preds = []\n",
    "index2 = 0\n",
    "\n",
    "start = dt.now()\n",
    "for i in range(359,359+len(testX)):\n",
    "    model.fit(trainX[:i],trainY[:i], epochs=1,batch_size=64,validation_split=0.1,verbose=0)\n",
    "    pred = model.predict(testX[index2].reshape(1,trainX.shape[1],trainX.shape[2]))\n",
    "    pred = pred[0][0] + df['score'].iloc[index2+365]\n",
    "    preds.append(pred)\n",
    "    index2 +=1\n",
    "    if i==359+(len(testX)-1):\n",
    "        \n",
    "        print( (dt.now() - start).seconds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE calcaulation \n",
    "\n",
    "a = np.sqrt(mean_squared_error(df['score'][366:], preds))\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
